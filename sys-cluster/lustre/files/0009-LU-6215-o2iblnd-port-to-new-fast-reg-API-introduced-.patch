From f1b1ef4f8af7751e1fc73b8f4ad2363b48159fa9 Mon Sep 17 00:00:00 2001
From: Li Dongyang <dongyang.li@anu.edu.au>
Date: Wed, 4 May 2016 13:11:15 -0400
Subject: [PATCH 09/19] LU-6215 o2iblnd: port to new fast reg API introduced in
 4.4

Remove the allocation of fastreg page list, as the page
vector is now private to the provider. Just pass tx_frags
to ib_map_mr_sg() and construct ib_reg_wr.
Defer the conversion of tx_frags to tx_pages and only do
it when the new API is not available.

Linux-commit: 4c67e2bfc8b7121d51434362fa7c2d012f8bcf1b
Linux-commit: 39bfc271bd687be2c8e396e976c0fb9a97963400

Signed-off-by: Li Dongyang <dongyang.li@anu.edu.au>
Change-Id: I5c62b0370ad6ddcc93102a29343491968e4446d0
Reviewed-on: http://review.whamcloud.com/19186
Tested-by: Jenkins
Reviewed-by: James Simmons <uja.ornl@yahoo.com>
Reviewed-by: Dmitry Eremin <dmitry.eremin@intel.com>
Tested-by: Maloo <hpdd-maloo@intel.com>
Reviewed-by: Oleg Drokin <oleg.drokin@intel.com>
---
 lnet/autoconf/lustre-lnet.m4    | 44 +++++++++++++++++++++++++
 lnet/klnds/o2iblnd/o2iblnd.c    | 71 ++++++++++++++++++++++++++++++++++-------
 lnet/klnds/o2iblnd/o2iblnd.h    | 11 ++++---
 lnet/klnds/o2iblnd/o2iblnd_cb.c | 39 ++++++++++------------
 4 files changed, 127 insertions(+), 38 deletions(-)

diff --git a/lnet/autoconf/lustre-lnet.m4 b/lnet/autoconf/lustre-lnet.m4
index a1498aa..5f90bca 100644
--- a/lnet/autoconf/lustre-lnet.m4
+++ b/lnet/autoconf/lustre-lnet.m4
@@ -418,6 +418,50 @@ AS_IF([test $ENABLEO2IB != "no"], [
 			[ib_alloc_fast_reg_mr is defined])
 	])
 ])
+
+# 4.4 added network namespace parameter for rdma_create_id()
+AS_IF([test $ENABLEO2IB != "no"], [
+	LB_CHECK_COMPILE([if 'rdma_create_id' wants five args],
+	rdma_create_id_5args, [
+		#ifdef HAVE_COMPAT_RDMA
+		#undef PACKAGE_NAME
+		#undef PACKAGE_TARNAME
+		#undef PACKAGE_VERSION
+		#undef PACKAGE_STRING
+		#undef PACKAGE_BUGREPORT
+		#undef PACKAGE_URL
+		#include <linux/compat-2.6.h>
+		#endif
+		#include <rdma/rdma_cm.h>
+	],[
+		rdma_create_id(NULL, NULL, NULL, 0, 0);
+	],[
+		AC_DEFINE(HAVE_RDMA_CREATE_ID_5ARG, 1,
+			[rdma_create_id wants 5 args])
+	])
+])
+
+# new fast registration API introduced in 4.4
+AS_IF([test $ENABLEO2IB != "no"], [
+	LB_CHECK_COMPILE([if 'ib_map_mr_sg' exists],
+	ib_map_mr_sg, [
+		#ifdef HAVE_COMPAT_RDMA
+		#undef PACKAGE_NAME
+		#undef PACKAGE_TARNAME
+		#undef PACKAGE_VERSION
+		#undef PACKAGE_STRING
+		#undef PACKAGE_BUGREPORT
+		#undef PACKAGE_URL
+		#include <linux/compat-2.6.h>
+		#endif
+		#include <rdma/ib_verbs.h>
+	],[
+		ib_map_mr_sg(NULL, NULL, 0, 0);
+	],[
+		AC_DEFINE(HAVE_IB_MAP_MR_SG, 1,
+			[ib_map_mr_sg exists])
+	])
+])
 ]) # LN_CONFIG_O2IB
 
 #
diff --git a/lnet/klnds/o2iblnd/o2iblnd.c b/lnet/klnds/o2iblnd/o2iblnd.c
index 57f51ca..1262268 100644
--- a/lnet/klnds/o2iblnd/o2iblnd.c
+++ b/lnet/klnds/o2iblnd/o2iblnd.c
@@ -1394,8 +1394,27 @@ kiblnd_destroy_fmr_pool(kib_fmr_pool_t *pool)
 {
         LASSERT (pool->fpo_map_count == 0);
 
-        if (pool->fpo_fmr_pool != NULL)
-                ib_destroy_fmr_pool(pool->fpo_fmr_pool);
+	if (fpo->fpo_is_fmr) {
+		if (fpo->fmr.fpo_fmr_pool)
+			ib_destroy_fmr_pool(fpo->fmr.fpo_fmr_pool);
+	} else {
+		struct kib_fast_reg_descriptor *frd, *tmp;
+		int i = 0;
+
+		list_for_each_entry_safe(frd, tmp, &fpo->fast_reg.fpo_pool_list,
+					 frd_list) {
+			list_del(&frd->frd_list);
+#ifndef HAVE_IB_MAP_MR_SG
+			ib_free_fast_reg_page_list(frd->frd_frpl);
+#endif
+			ib_dereg_mr(frd->frd_mr);
+			LIBCFS_FREE(frd, sizeof(*frd));
+			i++;
+		}
+		if (i < fpo->fast_reg.fpo_pool_size)
+			CERROR("FastReg pool still has %d regions registered\n",
+				fpo->fast_reg.fpo_pool_size - i);
+	}
 
         if (pool->fpo_hdev != NULL)
                 kiblnd_hdev_decref(pool->fpo_hdev);
@@ -1477,6 +1496,7 @@ static int kiblnd_alloc_freg_pool(kib_fmr_poolset_t *fps, kib_fmr_pool_t *fpo)
 		}
 		frd->frd_mr = NULL;
 
+#ifndef HAVE_IB_MAP_MR_SG
 		frd->frd_frpl = ib_alloc_fast_reg_page_list(fpo->fpo_hdev->ibh_ibdev,
 							    LNET_MAX_PAYLOAD/PAGE_SIZE);
 		if (IS_ERR(frd->frd_frpl)) {
@@ -1486,6 +1506,7 @@ static int kiblnd_alloc_freg_pool(kib_fmr_poolset_t *fps, kib_fmr_pool_t *fpo)
 			frd->frd_frpl = NULL;
 			goto out_middle;
 		}
+#endif
 
 #ifdef HAVE_IB_ALLOC_FAST_REG_MR
 		frd->frd_mr = ib_alloc_fast_reg_mr(fpo->fpo_hdev->ibh_pd,
@@ -1513,15 +1534,19 @@ static int kiblnd_alloc_freg_pool(kib_fmr_poolset_t *fps, kib_fmr_pool_t *fpo)
 out_middle:
 	if (frd->frd_mr)
 		ib_dereg_mr(frd->frd_mr);
+#ifndef HAVE_IB_MAP_MR_SG
 	if (frd->frd_frpl)
 		ib_free_fast_reg_page_list(frd->frd_frpl);
+#endif
 	LIBCFS_FREE(frd, sizeof(*frd));
 
 out:
 	list_for_each_entry_safe(frd, tmp, &fpo->fast_reg.fpo_pool_list,
 				 frd_list) {
 		list_del(&frd->frd_list);
+#ifndef HAVE_IB_MAP_MR_SG
 		ib_free_fast_reg_page_list(frd->frd_frpl);
+#endif
 		ib_dereg_mr(frd->frd_mr);
 		LIBCFS_FREE(frd, sizeof(*frd));
 	}
@@ -1625,6 +1650,28 @@ kiblnd_fmr_pool_is_idle(kib_fmr_pool_t *fpo, cfs_time_t now)
         return cfs_time_aftereq(now, fpo->fpo_deadline);
 }
 
+static int
+kiblnd_map_tx_pages(kib_tx_t *tx, kib_rdma_desc_t *rd)
+{
+	kib_hca_dev_t	*hdev;
+	__u64		*pages = tx->tx_pages;
+	int		npages;
+	int		size;
+	int		i;
+
+	hdev = tx->tx_pool->tpo_hdev;
+
+	for (i = 0, npages = 0; i < rd->rd_nfrags; i++) {
+		for (size = 0; size <  rd->rd_frags[i].rf_nob;
+			size += hdev->ibh_page_size) {
+			pages[npages++] = (rd->rd_frags[i].rf_addr &
+					   hdev->ibh_page_mask) + size;
+		}
+	}
+
+	return npages;
+}
+
 void
 kiblnd_fmr_pool_unmap(kib_fmr_t *fmr, int status)
 {
@@ -1666,13 +1713,16 @@ kiblnd_fmr_pool_unmap(kib_fmr_t *fmr, int status)
 }
 
 int
-kiblnd_fmr_pool_map(kib_fmr_poolset_t *fps, __u64 *pages, int npages,
-                    __u64 iov, kib_fmr_t *fmr)
+kiblnd_fmr_pool_map(kib_fmr_poolset_t *fps, kib_tx_t *tx, kib_rdma_desc_t *rd,
+		    __u32 nob, __u64 iov, kib_fmr_t *fmr)
 {
-        struct ib_pool_fmr *pfmr;
-        kib_fmr_pool_t     *fpo;
-        __u64               version;
-        int                 rc;
+	kib_fmr_pool_t *fpo;
+	__u64 *pages = tx->tx_pages;
+	__u64 version;
+	bool is_rx = (rd != tx->tx_rd);
+	bool tx_pages_mapped = 0;
+	int npages = 0;
+	int rc;
 
 again:
 	spin_lock(&fps->fps_lock);
@@ -1710,7 +1760,7 @@ again:
 				struct ib_reg_wr *wr;
 				int n;
 #else
-				struct ib_rdma_wr *wr;
+				struct ib_send_wr *wr;
 				struct ib_fast_reg_page_list *frpl;
 #endif
 				struct ib_mr *mr;
@@ -1755,9 +1805,8 @@ again:
 
 				wr = &frd->frd_fastreg_wr;
 				memset(wr, 0, sizeof(*wr));
-
 				wr->wr.opcode = IB_WR_REG_MR;
-				wr->wr.wr_id  = IBLND_WID_MR;
+				wr->wr.wr_id = IBLND_WID_MR;
 				wr->wr.num_sge = 0;
 				wr->wr.send_flags = 0;
 				wr->mr = mr;
diff --git a/lnet/klnds/o2iblnd/o2iblnd.h b/lnet/klnds/o2iblnd/o2iblnd.h
index 3baa255..60334b7 100644
--- a/lnet/klnds/o2iblnd/o2iblnd.h
+++ b/lnet/klnds/o2iblnd/o2iblnd.h
@@ -352,12 +352,12 @@ struct ib_rdma_wr {
 
 struct kib_fast_reg_descriptor { /* For fast registration */
 	struct list_head		 frd_list;
-	struct ib_rdma_wr		 frd_inv_wr;
+	struct ib_send_wr		 frd_inv_wr;
 #ifdef HAVE_IB_MAP_MR_SG
 	struct ib_reg_wr		 frd_fastreg_wr;
 #else
-	struct ib_rdma_wr		 frd_fastreg_wr;
-	struct ib_fast_reg_page_list    *frd_frpl;
+	struct ib_send_wr		 frd_fastreg_wr;
+	struct ib_fast_reg_page_list	*frd_frpl;
 #endif
 	struct ib_mr			*frd_mr;
 	bool				 frd_valid;
@@ -1125,8 +1125,9 @@ void kiblnd_unmap_rx_descs(kib_conn_t *conn);
 void kiblnd_pool_free_node(kib_pool_t *pool, struct list_head *node);
 struct list_head *kiblnd_pool_alloc_node(kib_poolset_t *ps);
 
-int  kiblnd_fmr_pool_map(kib_fmr_poolset_t *fps, __u64 *pages,
-                         int npages, __u64 iov, kib_fmr_t *fmr);
+int  kiblnd_fmr_pool_map(kib_fmr_poolset_t *fps, kib_tx_t *tx,
+			 kib_rdma_desc_t *rd, __u32 nob, __u64 iov,
+			 kib_fmr_t *fmr);
 void kiblnd_fmr_pool_unmap(kib_fmr_t *fmr, int status);
 
 int  kiblnd_tunables_init(void);
diff --git a/lnet/klnds/o2iblnd/o2iblnd_cb.c b/lnet/klnds/o2iblnd/o2iblnd_cb.c
index d25e45a..e400eb2 100644
--- a/lnet/klnds/o2iblnd/o2iblnd_cb.c
+++ b/lnet/klnds/o2iblnd/o2iblnd_cb.c
@@ -565,35 +565,22 @@ static int
 kiblnd_fmr_map_tx(kib_net_t *net, kib_tx_t *tx, kib_rdma_desc_t *rd, int nob)
 {
 	kib_hca_dev_t		*hdev;
-	__u64			*pages = tx->tx_pages;
 	kib_fmr_poolset_t	*fps;
-	int			npages;
-	int			size;
 	int			cpt;
 	int			rc;
-	int			i;
 
 	LASSERT(tx->tx_pool != NULL);
 	LASSERT(tx->tx_pool->tpo_pool.po_owner != NULL);
 
-	hdev  = tx->tx_pool->tpo_hdev;
-
-        for (i = 0, npages = 0; i < rd->rd_nfrags; i++) {
-                for (size = 0; size <  rd->rd_frags[i].rf_nob;
-                               size += hdev->ibh_page_size) {
-                        pages[npages ++] = (rd->rd_frags[i].rf_addr &
-                                            hdev->ibh_page_mask) + size;
-                }
-        }
-
+	hdev = tx->tx_pool->tpo_hdev;
 	cpt = tx->tx_pool->tpo_pool.po_owner->ps_cpt;
 
 	fps = net->ibn_fmr_ps[cpt];
-	rc = kiblnd_fmr_pool_map(fps, pages, npages, 0, &tx->fmr);
-        if (rc != 0) {
-                CERROR ("Can't map %d pages: %d\n", npages, rc);
-                return rc;
-        }
+	rc = kiblnd_fmr_pool_map(fps, tx, rd, nob, 0, &tx->fmr);
+	if (rc != 0) {
+		CERROR("Can't map %u pages: %d\n", nob, rc);
+		return rc;
+	}
 
 	/* If rd is not tx_rd, it's going to get sent to a peer, who will need
 	 * the rkey */
@@ -853,12 +840,20 @@ __must_hold(&conn->ibc_lock)
 
 		if (frd != NULL) {
 			if (!frd->frd_valid) {
-				wr = &frd->frd_inv_wr.wr;
-				wr->next = &frd->frd_fastreg_wr.wr;
+				wrq = &frd->frd_inv_wr;
+#ifdef HAVE_IB_MAP_MR_SG
+				wrq->next = &frd->frd_fastreg_wr.wr;
+			} else {
+				wrq = &frd->frd_fastreg_wr.wr;
+			}
+			frd->frd_fastreg_wr.wr.next = tx->tx_wrq;
+#else
+				wrq->next = &frd->frd_fastreg_wr;
 			} else {
 				wr = &frd->frd_fastreg_wr.wr;
 			}
-			frd->frd_fastreg_wr.wr.next = &tx->tx_wrq[0].wr;
+			frd->frd_fastreg_wr.next = tx->tx_wrq;
+#endif
 		}
 
 		LASSERTF(wrq->wr_id == kiblnd_ptr2wreqid(tx, IBLND_WID_TX),
-- 
2.8.2

